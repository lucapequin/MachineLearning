{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes\n",
    " 1. Luis Carlos Peña\n",
    " 2. Andrés Obando\n",
    " 3. Klaus Rodríguez\n",
    " 4. Alexander Vega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "# Used Vehicle Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- 1.2 Million listings scraped from TrueCar.com - Price, Mileage, Make, Model dataset from Kaggle: [data](https://www.kaggle.com/jpayne/852k-used-car-listings)\n",
    "- Each observation represents the price of an used car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise P1.1 (25%)\n",
    "\n",
    "## Notebook explaining the modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "data = pd.read_csv('dataTrain_carListings.csv')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataTrain_carListings.csv')\n",
    "data_test = pd.read_csv('dataTest_carListings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test= data_test\n",
    "data_test[\"State2\"]=pd.DataFrame(data_test.State.astype(\"category\").cat.codes)\n",
    "data_test[\"Make2\"]=pd.DataFrame(data_test.Make.astype(\"category\").cat.codes)\n",
    "data_test[\"Model2\"]=pd.DataFrame(data_test.Model.astype(\"category\").cat.codes)\n",
    "data_test3=data_test.drop([\"Make\",\"State\",\"Model\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to categorical variables State, Make and Model \n",
    "data[\"State\"] = data[\"State\"].astype('category')\n",
    "data[\"Make\"] = data[\"Make\"].astype('category')\n",
    "data[\"Model\"] = data[\"Model\"].astype('category')\n",
    "data[\"State_cat\"] = data[\"State\"].cat.codes\n",
    "data[\"Make_cat\"] = data[\"Make\"].cat.codes\n",
    "data[\"Model_cat\"] = data[\"Model\"].cat.codes\n",
    "\n",
    "# Extract feature and labels\n",
    "Y = data['Price']\n",
    "X = data.drop(['Price', 'State', 'Make', 'Model'], axis = 1)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we did?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before showing the model that we finally use, we want to mention all the algorithms that we execute:\n",
    "\n",
    "1. Bagging of Decision Tree. Best score in kaggle: 3.612\n",
    "2. Random forest. Best score in Kaggle: 3.521\n",
    "3. XGBoost. Best score in kaggle: 3.458\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we used an xgboost because it reported the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Begin tuning for XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tune the max_depth and min_child_weight parameters on a range of values. Later, we will refine these two choices with a smaller grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 60.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=150, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=1,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=100, silent=False,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'max_depth': [8, 16, 19, 24], 'min_child_weight': [1, 3, 5, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective = \"reg:linear\"\n",
    "seed = 100\n",
    "n_estimators = 150\n",
    "learning_rate = 0.1\n",
    "gamma = 0.1\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "reg_alpha = 1\n",
    "reg_lambda = 1\n",
    "silent = False\n",
    "\n",
    "parameters = {}\n",
    "parameters['objective'] = objective\n",
    "parameters['seed'] = seed\n",
    "parameters['n_estimators'] = n_estimators\n",
    "parameters['learning_rate'] = learning_rate\n",
    "parameters['gamma'] = gamma\n",
    "parameters['colsample_bytree'] = colsample_bytree\n",
    "parameters['reg_alpha'] = reg_alpha\n",
    "parameters['reg_lambda'] = reg_lambda\n",
    "parameters['silent'] = silent\n",
    "\n",
    "scores = []\n",
    "\n",
    "cv_params = {'max_depth': [8,16,19,24],\n",
    "             'min_child_weight': [1,3,5,7]\n",
    "            }\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        gamma = gamma,\n",
    "                                        subsample = subsample,\n",
    "                                        colsample_bytree = colsample_bytree,\n",
    "                                        reg_alpha = reg_alpha,\n",
    "                                        reg_lambda = reg_lambda,\n",
    "                                        silent = silent\n",
    "\n",
    "                                    ),\n",
    "                    \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 16, 'min_child_weight': 7}\n"
     ]
    }
   ],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'max_depth': 16, 'min_child_weight': 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Refine for max_depth and min_child_weight with a smaller grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 51.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=150, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=1,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=100, silent=False,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'max_depth': [15, 16, 17], 'min_child_weight': [6, 6.5, 7, 7.5, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = gbm.best_params_['max_depth']\n",
    "min_child_weight = gbm.best_params_['min_child_weight']\n",
    "parameters['max_depth'] = max_depth\n",
    "parameters['min_child_weight'] = min_child_weight\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'max_depth': [max_depth-1, max_depth, max_depth+1], ### max_depth=[15,16,17]\n",
    "             'min_child_weight': [min_child_weight-1, min_child_weight-0.5, min_child_weight, min_child_weight+0.5, min_child_weight+1]\n",
    "            } ### min_child_weight=[6,6.5,7,7.5,8]\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        gamma = gamma,\n",
    "                                        subsample = subsample,\n",
    "                                        colsample_bytree = colsample_bytree,\n",
    "                                        reg_alpha = reg_alpha,\n",
    "                                        reg_lambda = reg_lambda,\n",
    "                                        silent = silent,\n",
    "                                        \n",
    "                                    ),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    "                    \n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 15, 'min_child_weight': 7.5}\n"
     ]
    }
   ],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'max_depth': 15, 'min_child_weight': 7.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tuning gamma parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 15.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=15,\n",
       "       min_child_weight=7.5, missing=None, n_estimators=150, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=1,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=100, silent=False,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'gamma': [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = gbm.best_params_['max_depth']\n",
    "min_child_weight = gbm.best_params_['min_child_weight']\n",
    "parameters['max_depth'] = max_depth\n",
    "parameters['min_child_weight'] = min_child_weight\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'gamma': [i/10.0 for i in range(1,10,2)]}  ### gamma= [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        max_depth = max_depth,\n",
    "                                        min_child_weight = min_child_weight,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        subsample = subsample,\n",
    "                                        colsample_bytree = colsample_bytree,\n",
    "                                        reg_alpha = reg_alpha,\n",
    "                                        reg_lambda = reg_lambda,\n",
    "                                        silent = silent\n",
    "\n",
    "                                    ),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'gamma': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Set gamma parameter and tune the subsample and colsample_bytree parameters next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at 10% intervals from 60% to 100% for both subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = gbm.best_params_['gamma']\n",
    "parameters['gamma'] = gamma\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'subsample': [i/10.0 for i in range(6,11)], ### subsample=[0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "             'colsample_bytree': [i/10.0 for i in range(6,11)] ### colsample_bytree=[0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        max_depth = max_depth,\n",
    "                                        min_child_weight = min_child_weight,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        gamma = gamma,\n",
    "                                        reg_alpha = reg_alpha,\n",
    "                                        reg_lambda = reg_lambda,\n",
    "                                        silent = silent\n",
    "\n",
    "                                    ),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'colsample_bytree': 0.6, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Refine for subsample and colsample_bytree with a smaller grid of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at 5% intervals in some range around the best values found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = gbm.best_params_['subsample']\n",
    "colsample_bytree = gbm.best_params_['colsample_bytree']\n",
    "parameters['subsample'] = subsample\n",
    "parameters['colsample_bytree'] = colsample_bytree\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'subsample': [i/100.0 for i in range(int((subsample-0.1)*100.0), min(int((subsample+0.1)*100),105) , 5)], \n",
    "             'colsample_bytree': [i/100.0 for i in range(int((colsample_bytree-0.1)*100.0), min(int((subsample+0.1)*100),105), 5)]\n",
    "            }\n",
    "\n",
    "### subsample=[0.7, 0.75, 0.8, 0.85]\n",
    "### colsample_bytree=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85]\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        max_depth = max_depth,\n",
    "                                        min_child_weight = min_child_weight,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        gamma = gamma,\n",
    "                                        reg_alpha = reg_alpha,\n",
    "                                        reg_lambda = reg_lambda,\n",
    "                                        silent = silent\n",
    "\n",
    "                                    ),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'colsample_bytree': 0.6, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tuning reg_alpha and reg_lambda parameters¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsample_bytree = gbm.best_params_['colsample_bytree']\n",
    "subsample = gbm.best_params_['subsample']\n",
    "parameters['colsample_bytree'] = colsample_bytree\n",
    "parameters['subsample'] = subsample\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100], \n",
    "             'reg_lambda': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        max_depth = max_depth,\n",
    "                                        min_child_weight = min_child_weight,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        gamma = gamma,\n",
    "                                        colsample_bytree = colsample_bytree,\n",
    "                                        subsample = subsample,\n",
    "                                        silent = silent\n",
    "\n",
    "                                    ),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'reg_alpha': 1e-05, 'reg_lambda': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Refine parameters on a smaller grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at a smaller grid around the best values found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_alpha = gbm.best_params_['reg_alpha']\n",
    "reg_lambda = gbm.best_params_['reg_lambda']\n",
    "parameters['reg_alpha'] = reg_alpha\n",
    "parameters['reg_lambda'] = reg_lambda\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'reg_lambda': [reg_alpha*0.2, reg_alpha*0.5, reg_alpha, reg_alpha*2, reg_alpha*5], \n",
    "             'reg_alpha': [reg_lambda*0.2, reg_lambda*0.5, reg_lambda, reg_lambda*2, reg_lambda*5]\n",
    "            }\n",
    "\n",
    "### reg_lambda= [2.0000000000000003e-06, 5e-06, 1e-05, 2e-05, 5e-05]\n",
    "### reg_alpha= [0.2, 0.5, 1, 2, 5]\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(\n",
    "                                        objective = objective,\n",
    "                                        seed = seed,\n",
    "                                        n_estimators = n_estimators,\n",
    "                                        max_depth = max_depth,\n",
    "                                        min_child_weight = min_child_weight,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        gamma = gamma,\n",
    "                                        colsample_bytree = colsample_bytree,\n",
    "                                        subsample = subsample,\n",
    "                                        silent = silent\n",
    "\n",
    "                                    ),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Best parameters %s\" %gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters {'reg_alpha': 1, 'reg_lambda': 2e-05}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, we stopped looking for parameters because we were getting larger RMSE. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the best model was that used until the third step. That is, a model with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objective = \"reg:linear\"\n",
    "seed = 100\n",
    "n_estimators = 150\n",
    "learning_rate = 0.1\n",
    "gamma = 0.1\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "reg_alpha = 1\n",
    "reg_lambda = 1\n",
    "silent = False\n",
    "max_depth = 15\n",
    "min_child = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Lower the learning_rate and set a large num_estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step involves selecting a lower the learning_rate and set a large n_estimators  to ensure convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we choose:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators= [100,101,102,103,104,105,106,107,108,109,110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate = [0.5,0.75,0.1,0.105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the XGBOOST model with the best performance (score in kaggle=3458.122) is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.075, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=105, n_jobs=-1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=1,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=100, silent=False,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'max_depth': [15], 'min_child_weight': [7.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective = \"reg:linear\"\n",
    "seed = 100\n",
    "n_estimators = 105\n",
    "learning_rate = 0.075\n",
    "gamma = 0.1\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "reg_alpha = 1\n",
    "reg_lambda = 1\n",
    "silent = False\n",
    "\n",
    "parameters = {}\n",
    "parameters['objective'] = objective\n",
    "parameters['seed'] = seed\n",
    "parameters['n_estimators'] = n_estimators\n",
    "parameters['learning_rate'] = learning_rate\n",
    "parameters['gamma'] = gamma\n",
    "parameters['colsample_bytree'] = colsample_bytree\n",
    "parameters['reg_alpha'] = reg_alpha\n",
    "parameters['reg_lambda'] = reg_lambda\n",
    "parameters['silent'] = silent\n",
    "\n",
    "scores = []\n",
    "\n",
    "cv_params = {'max_depth': [15],\n",
    "             'min_child_weight': [7.5]\n",
    "            }\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(objective = objective,\n",
    "                                    seed = seed,\n",
    "                                    n_estimators = n_estimators,\n",
    "                                    learning_rate = learning_rate, \n",
    "                                    gamma = gamma,\n",
    "                                    subsample = subsample,\n",
    "                                    colsample_bytree = colsample_bytree,\n",
    "                                    reg_alpha = reg_alpha,\n",
    "                                    reg_lambda = reg_lambda,\n",
    "                                    silent = silent,n_jobs=-1),\n",
    "                    \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 3,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print('RMSE:', round(np.sqrt(metrics.mean_squared_error(predictions, y_test)),5))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 2176.5178 degrees.\n",
      "Accuracy = 89.24%.\n",
      "RMSE: 3459.99908\n"
     ]
    }
   ],
   "source": [
    "best_random = gbm.best_estimator_\n",
    "random_accuracy = evaluate(gbm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_model.pkl']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbm, 'gbm_model.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16744.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15744.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7719.280762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34369.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9116.747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7134.089355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9647.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17999.208984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15406.258789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15803.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20781.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30422.470703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45516.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36679.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13972.245117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11482.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23473.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25060.722656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9390.207031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20894.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19073.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17993.166016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24922.630859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22206.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12792.794922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20300.443359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16127.193359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22788.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7420.525391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29652.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249970</th>\n",
       "      <td>19403.564453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249971</th>\n",
       "      <td>6541.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249972</th>\n",
       "      <td>7486.653809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249973</th>\n",
       "      <td>14114.393555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249974</th>\n",
       "      <td>14978.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249975</th>\n",
       "      <td>22701.216797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249976</th>\n",
       "      <td>15569.056641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249977</th>\n",
       "      <td>20851.966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249978</th>\n",
       "      <td>17045.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249979</th>\n",
       "      <td>17098.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249980</th>\n",
       "      <td>9030.240234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249981</th>\n",
       "      <td>35104.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249982</th>\n",
       "      <td>20362.931641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249983</th>\n",
       "      <td>25643.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249984</th>\n",
       "      <td>37418.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249985</th>\n",
       "      <td>29802.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249986</th>\n",
       "      <td>32405.228516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249987</th>\n",
       "      <td>14401.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249988</th>\n",
       "      <td>7146.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249989</th>\n",
       "      <td>20667.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249990</th>\n",
       "      <td>16085.744141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249991</th>\n",
       "      <td>34224.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249992</th>\n",
       "      <td>20486.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249993</th>\n",
       "      <td>32296.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249994</th>\n",
       "      <td>29315.238281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>25180.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>13086.596680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>33955.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>28220.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>15371.968750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price\n",
       "0       16744.220703\n",
       "1       15744.460938\n",
       "2        7719.280762\n",
       "3       34369.234375\n",
       "4        9116.747070\n",
       "5        7134.089355\n",
       "6        9647.242188\n",
       "7       17999.208984\n",
       "8       15406.258789\n",
       "9       15803.610352\n",
       "10      20781.531250\n",
       "11      30422.470703\n",
       "12      45516.015625\n",
       "13      36679.730469\n",
       "14      13972.245117\n",
       "15      11482.859375\n",
       "16      23473.003906\n",
       "17      25060.722656\n",
       "18       9390.207031\n",
       "19      20894.687500\n",
       "20      19073.996094\n",
       "21      17993.166016\n",
       "22      24922.630859\n",
       "23      22206.429688\n",
       "24      12792.794922\n",
       "25      20300.443359\n",
       "26      16127.193359\n",
       "27      22788.617188\n",
       "28       7420.525391\n",
       "29      29652.109375\n",
       "...              ...\n",
       "249970  19403.564453\n",
       "249971   6541.440430\n",
       "249972   7486.653809\n",
       "249973  14114.393555\n",
       "249974  14978.421875\n",
       "249975  22701.216797\n",
       "249976  15569.056641\n",
       "249977  20851.966797\n",
       "249978  17045.613281\n",
       "249979  17098.839844\n",
       "249980   9030.240234\n",
       "249981  35104.875000\n",
       "249982  20362.931641\n",
       "249983  25643.970703\n",
       "249984  37418.375000\n",
       "249985  29802.169922\n",
       "249986  32405.228516\n",
       "249987  14401.671875\n",
       "249988   7146.515625\n",
       "249989  20667.179688\n",
       "249990  16085.744141\n",
       "249991  34224.628906\n",
       "249992  20486.687500\n",
       "249993  32296.539062\n",
       "249994  29315.238281\n",
       "249995  25180.269531\n",
       "249996  13086.596680\n",
       "249997  33955.570312\n",
       "249998  28220.830078\n",
       "249999  15371.968750\n",
       "\n",
       "[250000 rows x 1 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test3 = np.array(data_test3)\n",
    "y_pred = pd.DataFrame(gbm.best_estimator_.predict(data_test3))\n",
    "y_pred.rename(columns={0:'Price'}, inplace=True)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('test_submission.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise P1.2 (50%)\n",
    "\n",
    "Create an API of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API on AWS\n",
    "Following the screnshots from the API hosted on AWS server.\n",
    "\n",
    "API link:http://18.191.28.236:5000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/AP_AWS0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/AP_AWS1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use the API directly with the URL, can use:\n",
    "\n",
    "Example:  \n",
    "http://18.191.28.236:5000/pricepredict/?year=2018&mileage=1000&state=MD&make=Nissan&model=MuranoAWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/AP_AWS2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API local:\n",
    "\n",
    "The following images shows the API function on local machine:\n",
    "\n",
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/API1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try the local API:**\n",
    "\n",
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/API2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The arguments entered:**\n",
    "\n",
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/API3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the API:**\n",
    "\n",
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/API4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the answer:**\n",
    "\n",
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/API5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the API directly with the routhe and parameters:**\n",
    "\n",
    "![](https://raw.githubusercontent.com/andaoba/MachineLearningCourse/master/Capturas_API_local/API6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
