Tipos de árboles de decisión y aplicaciones. Un árbol de decisión es uno de los algoritmos de ML de tipo supervisado más confiable, este mecanismo consiste en generar varias reglas que se van aplicando sobre las nuevas muestras o nuevos datos con el fin de decidir que clasificación tendrán según los atributos anteriormente ingresados. El árbol está formado por un conjunto de nodos de decisión y nodos de respuesta. Un nodo de decisión tiene dos o más ramas que salen de él y representan los valores que puede tomar cada atributo, un nodo de respuesta indica la clasificación dada o que se quiere dar.
En general existen tres tipos de árboles de decisión que son utilizados para la minería de datos: Árboles de Clasificación, Árboles de Regresión y Árboles de clasificación y regresión. El primero devuelve la clase a la que pertenecen los datos, el segundo devuelve un número real y el tercero que es una combinación de los dos anteriores. Así mismo existen técnicas que utilizan más de un árbol para su decisión: Baggin, Random Forest, Arboles Impulsados y Rotation Forest. Baggin construye diferentes Árboles repitiendo varias veces el muestreo con los datos de entrenamiento y luego halla un consenso entre los árboles, Randon Forest utiliza series de árboles con el fin de mejorar la clasificación, Árboles Impulsados se utilizan para problemas de clasificación y regresión y Rotation Forest en el que cada árbol es entrenado utilizando Análisis de Componentes Principales.
Existen también algunos algoritmos específicos de árboles de decisión:
•	ID3 (Iterative Dichotomiser 3) utiliza óptimos locales por medio de la entropía, pero puede sobreestimar los datos.
•	C4.5 (Sucesor de ID3). Selecciona variables por medio de Entrpy info-again mejorando el ID3 como clasificador
•	ACR (Arboles de Clasificación y Regresión) Para seleccionar las variables usa los algoritmos GINI index o el Twoing criteria
•	Chaid (Detector automático de Chi-Cuadrado) es usado para predecir grupos de consumidores. Usa Chi-Cuadrado para la selección de variables.
•	Mars Extiende los árboles de decisión para operar con datos numéricos con no linealidades e interacciones entre variables.
•	Arboles de inferencia Condicional. Aproximación basada en estadística que usa pruebas no paramétricas para la partición, es insesgado y no requiere poda.
